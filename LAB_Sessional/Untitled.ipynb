{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f3d227-47f6-49cc-98fa-4443cca79999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import gymnasium as gym  # Use gymnasium (modern version of gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f373be6-d358-4912-872d-551b5f1d36e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create the CarRacing-v2 environment\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCarRacing-v3\u001b[39m\u001b[38;5;124m'\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define the DQN model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the CarRacing-v2 environment\n",
    "env = gym.make('CarRacing-v3', render_mode='human')\n",
    "\n",
    "# Define the DQN model\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(96, 96, 3)),  # Process image input\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='linear')  # 3 possible actions: left, right, accelerate\n",
    "    ])\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
    "    return model\n",
    "\n",
    "# Define the DQN agent\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.model = build_model()\n",
    "        self.target_model = build_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95  # Discount factor\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.choice([0, 1, 2])  # Random action\n",
    "        q_values = self.model.predict(np.expand_dims(state, axis=0), verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "    \n",
    "    def replay(self, batch_size=32):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target += self.gamma * np.amax(self.target_model.predict(np.expand_dims(next_state, axis=0), verbose=0))\n",
    "            target_f = self.model.predict(np.expand_dims(state, axis=0), verbose=0)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(np.expand_dims(state, axis=0), target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "# Train the agent\n",
    "def train_dqn(episodes=500):\n",
    "    agent = DQNAgent()\n",
    "    for episode in range(episodes):\n",
    "        state, _ = env.reset()  # Updated reset method\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, terminated, truncated, _ = env.step([0, action - 1, 0.2])  # Updated step\n",
    "            done = terminated or truncated\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "        agent.replay()\n",
    "        agent.update_target_model()\n",
    "        print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}, Epsilon: {agent.epsilon:.4f}\")\n",
    "    return agent\n",
    "\n",
    "# Run training\n",
    "if __name__ == \"__main__\":\n",
    "    trained_agent = train_dqn(episodes=100)  # Reduce episodes for faster testing\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c58d14-643e-4839-9192-c050294e8068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c31061-1e30-4b20-863f-6abb14adbf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
